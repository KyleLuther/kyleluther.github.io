---
# Jekyll uses index.md as landing page, but i want landing page to be about.
# Feel free to add content and custom Front Matter to this file.
# To modify the layout, see https://jekyllrb.com/docs/themes/#overriding-theme-defaults
layout: page
title: About
permalink: /
redirect_from: /about/
---
<!-- use 10pt font -->
<style type="text/css">
  body{
  font-size: 11pt;
}
</style>

![image](/assets/circular_profile.png){:height="175px" width="175px" style="float: right"}

Hi!

I'm a postdoctoral researcher at Princeton in the group led by [Sebastian Seung](https://seunglab.org/){:target="\_blank"}. My current research interests lie at the intersection of AI, computer vision and invariant representation learning. 

[email](mailto:kluther@princeton.edu) &nbsp; \| &nbsp;  [CV](/assets/CV.pdf) &nbsp; \| &nbsp; [Google Scholar](https://scholar.google.com/citations?hl=en&view_op=list_works&gmla=AJsN-F5e0yPGmYrQrZ9lske_v4RPq7xURWD5Z9iJGyfnmTQL4rYTaBSksBIrwBWBx732XmQAtC4IklkW_Y7KQPO32WMjzxA06w&user=JX_K0-QAAAAJ) &nbsp; \| &nbsp; [GitHub](https://github.com/KyleLuther)
{: style="text-align: center"}

<br clear="all" />
### Research
<!-- Images: hxw = 175x225 -->
![image](/assets/tomography.png){:height="125px" width="150px"
align="left" style="padding-bottom: 75px; padding-right: 38px; padding-left: 37px"}
[Serial section electron tomography at scale](https://github.com/KyleLuther/SerialTomo)  
*Current research*

Large scale serial section microscopy currently faces two major challenges. One, the sections are too thin: at 40nm thick, the sections tend to crack, fold and generally fall apart. Two: the sections are too thick: neurites are occasionally smaller than 40nm and higher resolution is needed to trace them through adjacent sections. Can we solve both problems with serial section tomography to allow physically thicker but virtually thinner sections?

![image](/assets/sparsecoding_overview.png){:height="125px" width="200px"
align="left" style="padding-bottom: 50px; padding-right: 25px"}
[Sensitivity of sparse codes to image distortions](https://arxiv.org/abs/2204.07466)  
**Kyle Luther**, H. Sebastian Seung  
Neural Computation, 2022

We identify and explain the following behavior: the representations generated by popular sparse coding amplify input pixel distortions.

<br clear="all" />
![image](/assets/ksm_overview.png){:height="125px" width="175px"
align="left" style="padding-bottom: 50px; padding-right: 25px; padding-left: 25px"}
[Kernel similarity matching with Hebbian neural networks](https://arxiv.org/abs/2204.07475)  
**Kyle Luther**, H. Sebastian Seung  
Neurips, 2022

We derive a network with online Hebbian learning rules capable of performing kernel similarity matching.

<br clear="all" />
![image](/assets/metriclearning3d_overview.png){:height="150px" width="200px"
align="left" style="padding-bottom: 25px; padding-right: 25px"}
[Learning and segmenting dense voxel embeddings for 3D neuron reconstruction](https://ieeexplore.ieee.org/document/9489304)  
Kisuk Lee, Ran Lu, **Kyle Luther**, H. Sebastian Seung  
IEEE Transactions on Medical Imaging, 2021

We use convolutional networks to assign an embedding vector to every voxel (3D pixel). These embedding vectors which are then used to segment 3D volumetric microscopy images.

<br clear="all" />
![image](/assets/reexamining_overview.png){:height="150px" width="150px"
align="left" style="padding-right: 50px; padding-left: 25px; padding-bottom: 25px"}
[Reexamining the principle of mean-variance preservation for neural network initialization](https://journals.aps.org/prresearch/abstract/10.1103/PhysRevResearch.2.033135)  
**Kyle Luther**, H. Sebastian Seung  
Physical Review Research, 2020

We prove that in a wide ReLU network the variance of individual neurons decays to zero with depth, even when networks are initialized with the popular Kaiming initialization.

<br clear="all" />
![image](/assets/cgame_overview.png){:height="100px" width="150px"
align="left" style="padding-right: 38px; padding-left: 37px; padding-bottom: 75px"}
[Unsupervised learning by a softened correlation game: duality and convergence](https://ieeexplore.ieee.org/abstract/document/9048957)  
**Kyle Luther**, Runzhe Yang, H. Sebastian Seung  
The Fifty-Third Asilomar Conference on Signals, Systems & Computers, 2019

We analyze convergence and duality guarantees in a recently proposed model of cortical learning which pits excitatory and inhibitory neurons against each other in a two player zero-sum game.

<br clear="all" />
![image](/assets/metriclearning_overview.png){:height="150px" width="150px"
align="left" style="padding-right: 38px; padding-left: 37px; padding-bottom: 75px"}
[Learning metric graphs for neuron segmentation in electron microscopy images](https://ieeexplore.ieee.org/document/8759576)  
**Kyle Luther**, H. Sebastian Seung  
IEEE 16th International Symposium on Biomedical Imaging, 2019

We use convolutional networks to assign an embedding vector to every pixel in 2D micrscopy images of brain tissue. These embedding vectors are then used to segment every neuron.

<br clear="all" />
Built with Jekyll
